{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "import regex as re\n",
    "import time\n",
    "import os\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import FastText\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    return simple_preprocess(text)\n",
    "\n",
    "def read_corpus(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            yield preprocess_text(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file_path = 'shona_corpus_E.txt'\n",
    "# Read and preprocess the corpus\n",
    "sentences = list(read_corpus(corpus_file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['mavambo',\n",
       "  'kusikwa',\n",
       "  'kwezvinhu',\n",
       "  'zvose',\n",
       "  'pakutanga',\n",
       "  'mwari',\n",
       "  'akasika',\n",
       "  'denga',\n",
       "  'nepasi'],\n",
       " ['zvino',\n",
       "  'rakanga',\n",
       "  'risina',\n",
       "  'chiumbo',\n",
       "  'risina',\n",
       "  'uye',\n",
       "  'rakanga',\n",
       "  'riri',\n",
       "  'pamusoro',\n",
       "  'pehwenje'],\n",
       " ['mweya', 'wamwari', 'wakanga', 'uchidzengerera', 'pamusoro', 'pemvura']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 3669.8039407730103 minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Train FastText model\n",
    "model = FastText(\n",
    "    sentences, \n",
    "    vector_size=50,  # Higher dimension for better performance\n",
    "    window=5, \n",
    "    min_count=5, \n",
    "    workers=4, \n",
    "    sg=1,  # Skip-gram model\n",
    "    epochs=100,  # More epochs for thorough training\n",
    "    bucket=2000000,  # Large bucket size for handling subwords\n",
    "    min_n=3,  # Minimum length of char n-grams\n",
    "    max_n=6   # Maximum length of char n-grams\n",
    ")\n",
    "end_time = time.time()\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Time taken:\", elapsed_time, \"minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"shona_fasttext_50d.model\")\n",
    "model.wv.save(\"shona_fasttext_vectors_50d.kv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText(vocab=107228, vector_size=50, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = load_fasttext_model(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity task evaluation:\n",
      "murume-mukadzi: Human score = 0.8, Model score = 0.8765901327133179\n",
      "mwana-mukomana: Human score = 0.6, Model score = 0.7090246081352234\n"
     ]
    }
   ],
   "source": [
    "def evaluate_similarity(model, word_pairs):\n",
    "    similarity_scores = []\n",
    "    for word1, word2, score in word_pairs:\n",
    "        similarity_score = model.wv.similarity(word1, word2)\n",
    "        similarity_scores.append((word1, word2, score, similarity_score))\n",
    "    print(\"Similarity task evaluation:\")\n",
    "    for word1, word2, human_score, model_score in similarity_scores:\n",
    "        print(f\"{word1}-{word2}: Human score = {human_score}, Model score = {model_score}\")\n",
    "\n",
    "# Example similarity word pairs\n",
    "similarity_word_pairs = [(\"murume\", \"mukadzi\", 0.8), (\"mwana\", \"mukomana\", 0.6)]\n",
    "evaluate_similarity(model, similarity_word_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mukomana is to amai as musikana is to: naamai, vevana, vamargaret, vaninina, namai\n"
     ]
    }
   ],
   "source": [
    "def perform_analogical_reasoning(model, a, b, c, topn=5):\n",
    "    d = model.wv[b] - model.wv[a] + model.wv[c]\n",
    "    closest_words = model.wv.similar_by_vector(d, topn=topn + 3)  # Add extra to ensure we get at least topn unique words\n",
    "    result_words = [word for word, _ in closest_words if word not in [a, b, c]]\n",
    "    return result_words[:topn]\n",
    "\n",
    "# Example usage\n",
    "a = \"mukomana\"  # man\n",
    "b = \"amai\"   # king\n",
    "c = \"musikana\" # woman\n",
    "\n",
    "predicted_words = perform_analogical_reasoning(model, a, b, c)\n",
    "if predicted_words:\n",
    "    print(f\"{a} is to {b} as {c} is to: {', '.join(predicted_words)}\")\n",
    "else:\n",
    "    print(\"No suitable words found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mukadzi is to ambuya as murume is to: vokwanhingi, mhamha, amainini, hamenowo, mbuya\n"
     ]
    }
   ],
   "source": [
    "# Perform Analogical Reasoning\n",
    "def perform_analogical_reasoning(model, a, b, c, topn=5):\n",
    "    # Calculate the vector d as b - a + c\n",
    "    d = model.wv[b] - model.wv[a] + model.wv[c]\n",
    "    \n",
    "    # Find the words that best complete the analogy\n",
    "    closest_words = model.wv.similar_by_vector(d, topn=topn + 4)  # Add extra to ensure we get at least topn unique words\n",
    "    result_words = [word for word, _ in closest_words if word not in [a, b, c]]\n",
    "    \n",
    "    # Ensure we return exactly 'topn' words\n",
    "    return result_words[:topn]\n",
    "\n",
    "# Example usage\n",
    "a = \"mukadzi\"  # man\n",
    "b = \"ambuya\"   # king\n",
    "c = \"murume\" # woman\n",
    "\n",
    "predicted_words = perform_analogical_reasoning(model, a, b, c)\n",
    "if predicted_words:\n",
    "    print(f\"{a} is to {b} as {c} is to: {', '.join(predicted_words)}\")\n",
    "else:\n",
    "    print(\"No suitable words found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('kutongwa', 0.7632266879081726), ('nokutonga', 0.7399135828018188), ('kwamwari', 0.7255278825759888), ('kupona', 0.7216368317604065), ('kugumisa', 0.7109279632568359), ('kurwira', 0.7098906636238098), ('musimba', 0.7028589248657227), ('huchakurumidza', 0.6985704302787781), ('kururama', 0.6965538263320923), ('kushora', 0.6942458152770996)]\n"
     ]
    }
   ],
   "source": [
    "# Test similarity\n",
    "similar_words = model.wv.most_similar(\"kutonga\", topn=10)\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blessmore import load_fasttext_model,clean_text_from_file,train_fasttext_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = load_fasttext_model(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.67073941e-01 -1.40327856e-01  2.46757850e-01 -1.19709358e-01\n",
      "  3.33165154e-02 -1.27217919e-01 -2.70771205e-01 -2.94649298e-03\n",
      " -4.37316597e-01  3.24908376e-01  1.84016023e-02 -4.91404563e-01\n",
      "  6.82000518e-01 -9.34935957e-02 -3.72670740e-01  2.63547480e-01\n",
      " -1.18853301e-01 -7.24551618e-01  2.77097493e-01 -2.68609971e-01\n",
      " -3.52165788e-01 -4.62470114e-01  1.93486243e-01 -4.70782608e-01\n",
      "  1.01021312e-01  5.08193195e-01  2.36431822e-01 -3.45228672e-01\n",
      "  8.06312859e-02  2.12296277e-01 -3.76502760e-02  2.87234217e-01\n",
      "  3.94492626e-01  2.65002131e-01  4.81813252e-01 -3.98817480e-01\n",
      " -2.38584206e-01 -4.00748253e-01  2.77814418e-01 -2.83835769e-01\n",
      "  1.32060057e-04  1.09159574e-01  5.09238124e-01 -1.78759381e-01\n",
      "  3.66199493e-01 -7.16258585e-01 -1.49325162e-01 -1.98036402e-01\n",
      "  1.75683662e-01  2.44939819e-01]\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "word_vector = model.wv['mwari']\n",
    "print(word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for cleaning: 0.015781641006469727 seconds\n",
      "Time taken for training: 1.3132991790771484 seconds\n"
     ]
    }
   ],
   "source": [
    "corpus_file_path = 'D.txt'\n",
    "vector_size = 100  # Specify the dimension you want to train\n",
    "model = train_fasttext_model(corpus_file_path, vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.012693405151367188 seconds\n"
     ]
    }
   ],
   "source": [
    "input_file = 'D.txt'\n",
    "output_file = 'cleaned_shona_corpus.txt'\n",
    "clean_text_from_file(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
