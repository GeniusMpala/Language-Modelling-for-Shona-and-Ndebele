{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "# Load the pre-trained FastText model\n",
    "model = FastText.load(\"shona_fasttext_50d.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText(vocab=107228, vector_size=50, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12694322,  0.07500106,  0.12631156, -0.04586631, -0.04868254,\n",
       "        0.03402508, -0.06310038, -0.22078694, -0.21315102, -0.1385409 ,\n",
       "       -0.08130909,  0.01712037,  0.00082262,  0.1144122 , -0.08897744,\n",
       "        0.06036587, -0.01094372, -0.04460265,  0.02624194, -0.02349709,\n",
       "       -0.2157254 , -0.1279458 ,  0.11800685,  0.17434277,  0.21540494,\n",
       "       -0.03997247,  0.07399303,  0.02664708,  0.04788842,  0.0707145 ,\n",
       "        0.1012168 , -0.17522267,  0.01179009, -0.00324907,  0.21237735,\n",
       "       -0.18660948, -0.09451319,  0.03652973,  0.04196132,  0.06683815,\n",
       "       -0.08080963,  0.19009183,  0.19420347, -0.19389336, -0.06921295,\n",
       "       -0.22054118, -0.36662328, -0.26440015, -0.03413467,  0.3482807 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_vector = model.wv.get_vector(\"baba\", norm=True)\n",
    "normed_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('kushamiswa', 0.7706368565559387), ('kutaurira', 0.769014298915863), ('kungotaura', 0.7551091909408569), ('kungotaurawo', 0.748419463634491), ('kutaurawo', 0.7469412684440613)]\n"
     ]
    }
   ],
   "source": [
    "# Test similarity\n",
    "similar_words = model.wv.most_similar(\"kutaura\", topn=5)\n",
    "print(similar_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for 'baba': [ 0.552565    0.3264685   0.5498155  -0.19964926 -0.2119079   0.1481061\n",
      " -0.27466658 -0.9610528  -0.9278148  -0.60304797 -0.35392636  0.07452245\n",
      "  0.00358075  0.4980193  -0.3873056   0.26276368 -0.04763639 -0.19414872\n",
      "  0.11422727 -0.10227935 -0.93902063 -0.556929    0.5136663   0.7588882\n",
      "  0.9376257  -0.17399421  0.32208067  0.11599078  0.20845118  0.30780968\n",
      "  0.4405817  -0.76271826  0.05132053 -0.01414272  0.92444706 -0.81228334\n",
      " -0.41140184  0.15900852  0.18265137  0.29093656 -0.35175234  0.8274415\n",
      "  0.8453388  -0.843989   -0.30127367 -0.959983   -1.5958567  -1.1508946\n",
      " -0.14858314  1.5160142 ]\n"
     ]
    }
   ],
   "source": [
    "# Function to generate embeddings for a given word\n",
    "def generate_embedding(word):\n",
    "    try:\n",
    "        embedding = model.wv[word]\n",
    "        return embedding\n",
    "    except KeyError:\n",
    "        print(f\"Word '{word}' not found in the vocabulary.\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "word = \"baba\"\n",
    "embedding = generate_embedding(word)\n",
    "if embedding is not None:\n",
    "    print(f\"Embedding for '{word}':\", embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Ndakanganwa kushandisa tsamba.\n",
      "Embeddings for words in the sentence:\n",
      "\tNdakanganwa: [ 0.03009197 -0.13062145  0.12644638 -0.04077367 -0.16770773 -0.03909929\n",
      "  0.61177605 -0.2980716  -0.381827    0.5352361  -0.18716507 -0.5672541\n",
      "  0.32401004  0.01221917 -0.31774318 -0.05692827  0.2557482   0.14748138\n",
      " -0.00819545 -0.01216372  0.01273371 -0.73280156  0.3290436  -0.11633662\n",
      "  0.5631776   0.4493094   0.04626599 -0.53889143  0.20818871 -0.43546963\n",
      "  0.11975758 -0.37782896  0.6777281   0.5698752   0.00269621 -0.51186734\n",
      " -0.35704935 -0.42260015  0.187949   -0.34017244 -0.0021306   0.19654167\n",
      "  0.41382745 -0.636411   -0.07520644 -0.60327196 -0.23389171 -0.4271142\n",
      "  0.3907566   0.20353974]\n",
      "\tkushandisa: [-0.41028827 -0.329545    0.11068455 -0.03628904  0.5987615   0.5041354\n",
      "  0.2993329   0.00534615  0.26151845  0.7343734  -0.30558738 -0.24025562\n",
      " -0.72723335  0.31499863 -0.6281841  -0.32758382 -0.20452274  0.23820212\n",
      "  0.01292126  0.06968886  0.5119832  -0.33474746  0.70690125  0.37671658\n",
      " -0.6250054   0.81987464  0.08969912  0.17006862  0.3906654   0.10802693\n",
      " -0.18153085 -0.4751722   0.7074194   0.37669867  0.38795367 -0.70723987\n",
      " -0.3312932  -0.52426755 -0.4380841  -0.91930574  0.15280397  0.6579584\n",
      "  0.08367249 -0.5272251   0.17859751 -1.2849673   0.14479296  0.24013585\n",
      "  0.08564614  0.05820247]\n",
      "\ttsamba: [-1.98553249e-01 -5.08757949e-01  4.15106416e-01  8.03024769e-01\n",
      " -1.68475151e-01  5.96477389e-02 -6.67969362e-05 -6.30134404e-01\n",
      " -7.49852538e-01  1.03462331e-01  7.50598669e-01 -8.11400712e-01\n",
      " -2.73744345e-01  1.81376994e-01  6.23194873e-01 -3.74855042e-01\n",
      " -2.07277805e-01 -1.51325017e-01  2.81303227e-01 -1.75290123e-01\n",
      "  7.33635902e-01 -6.00555897e-01 -1.52251005e-01  1.09463549e+00\n",
      " -1.28238058e+00  9.55608606e-01  4.16029602e-01  1.17865816e-01\n",
      "  7.17068911e-01 -8.05027485e-02 -2.54630715e-01 -7.50301123e-01\n",
      "  5.74336767e-01  3.30295473e-01  1.12961374e-01 -5.37425399e-01\n",
      " -3.99383307e-02 -3.05387259e-01  1.02325782e-01 -7.93136001e-01\n",
      " -9.44472432e-01  2.48040989e-01  6.31469190e-01 -6.52885139e-01\n",
      "  1.76506668e-01 -8.57193828e-01  1.04078986e-02 -8.46793294e-01\n",
      "  4.77125853e-01  4.57902700e-01]\n",
      "\t.: [ 0.01686053  0.01679178  0.01255845  0.00920964  0.01229837  0.01313791\n",
      " -0.01748926  0.01971267  0.01324598  0.00737016 -0.01815464  0.01536085\n",
      " -0.0046414   0.01275101  0.01056694  0.00501434 -0.01373173 -0.01937773\n",
      " -0.01645166  0.00743307  0.0100628  -0.01119597  0.00863419  0.0072488\n",
      "  0.00812203 -0.01939026  0.01863839  0.01564768  0.00216114  0.01543188\n",
      "  0.01198145  0.00095703  0.0067538   0.01125299 -0.0149384   0.00403031\n",
      " -0.00797083  0.01764007 -0.0027599  -0.01099936  0.01505769  0.01872787\n",
      "  0.01663026  0.01722633  0.01960812 -0.0110198  -0.00577967  0.01991023\n",
      "  0.01213146  0.01784239]\n",
      "Sentence: Vatengesi vachabvunza ko ndikati kune zvaitwa sei.\n",
      "Embeddings for words in the sentence:\n",
      "\tVatengesi: [-0.16257793  0.00407063  0.3517738  -0.3190759  -0.06957784 -0.14874707\n",
      " -0.00288857 -0.37292668 -0.28779283  0.3053703   0.05143461  0.0034659\n",
      " -0.28594875 -0.27348104 -0.13328363 -0.36301863 -0.60243946  0.3414081\n",
      "  0.77026767  0.19917116 -0.2879318  -0.61811656  0.8363607   0.03138367\n",
      " -0.25522515 -0.12662928  0.33436143  0.02437662  0.17551719 -0.19424884\n",
      "  0.03469775 -0.3750497   0.4837432   0.6131828   0.56236607 -0.09040375\n",
      "  0.20472807  0.21219644  0.07755709 -0.04703481 -0.04251176  0.87156475\n",
      "  0.00135369 -0.04532474  0.00450457 -0.6248706   0.2206939  -0.3651672\n",
      "  0.51787865  0.33107758]\n",
      "\tvachabvunza: [-0.39016694  0.29322976  0.44247666 -0.30778033  0.73454714 -0.00716174\n",
      " -0.39002782  0.10945047 -0.17976987  0.1460823   0.40628904  0.3764703\n",
      " -0.19235575  0.25398147 -0.17827487  0.25913015 -0.3355588  -0.24325535\n",
      " -0.04481563 -0.0401751  -0.017076   -0.20719333  0.5460555   0.46305588\n",
      "  0.6572561  -0.03683871  0.5887     -0.3190758   0.06323216 -0.250884\n",
      "  0.2704856  -0.6087964   0.21237765  0.60175765 -0.00308887 -0.44573265\n",
      "  0.00266335 -0.5227539  -0.53067297 -0.04018444 -0.38232976  0.7855813\n",
      "  0.5242065  -1.164383   -0.3187107  -0.282968   -0.4197751  -0.16025436\n",
      "  0.5254853   0.42499086]\n",
      "\tko: [ 3.336311    1.3618742   2.2128642  -0.6724372  -1.1805831   1.5167829\n",
      " -0.9727463  -1.0948919  -1.9549536  -1.4993662   1.718026   -0.5444223\n",
      " -0.9416039  -0.9942556   0.08480302 -0.144621   -0.65735763  0.9853255\n",
      " -0.59972143  0.192622   -0.60193515 -3.2200823   0.34333107  0.4559621\n",
      " -0.33777037  0.8437846  -0.14173162  0.31352225  2.7494469  -0.5300905\n",
      "  0.36608925 -1.7179623  -2.0181735  -1.2988216   0.9429548   2.1997561\n",
      "  0.05378851  0.542927    0.04499932 -0.504894   -0.00676972 -0.36798772\n",
      " -0.10940091 -0.5086351   0.01411443 -1.8612546  -1.7236315  -2.7754462\n",
      "  0.8548133   0.46306023]\n",
      "\tndikati: [ 0.26661685  0.34584755  0.41476333  0.10235977 -0.22990297  0.05702223\n",
      "  0.52016246 -0.3086528  -0.46867368 -0.01152431 -0.21555556  0.00781856\n",
      "  0.45008603  0.1081708  -0.05297107 -0.02416503 -0.33099517 -0.26930887\n",
      "  0.5372826   0.8903459   0.31002727 -0.13838841  0.7798994   0.22608297\n",
      "  0.6036484   0.47633004 -0.12902997 -0.01411045  0.31800747 -0.16232957\n",
      " -0.5333354  -0.8557635  -0.2077563   0.23756015  0.30660468 -0.63603055\n",
      " -0.32154647 -0.65741765  0.1419635  -0.29041648  0.71617675 -0.0518531\n",
      "  0.38577282 -0.681524    0.0574095  -0.4241497   0.07862592 -0.5932708\n",
      "  0.6297111   0.8300594 ]\n",
      "\tkune: [ 0.12825371  0.05118616  0.17694293 -0.12103961  0.5401965   0.02706058\n",
      "  0.01690676  0.35614318 -0.43127486  0.22208907  0.34148413  0.34374037\n",
      " -0.2398272   0.00546442 -0.51016974 -0.292922    0.04055957  0.3137336\n",
      "  0.31454247  0.06061356  0.19492707 -0.78744715  0.70003045  0.00672312\n",
      " -0.14865078 -0.3653983   0.47947684 -0.08252423  0.3624663   0.13398694\n",
      " -0.37334824 -0.49465302  1.1313404   0.56818426  0.06450034 -0.65624654\n",
      "  0.37800062  0.02523123 -0.301422   -0.17322895 -0.07287932  0.68621796\n",
      " -0.7511856  -0.45113504 -0.26262543 -0.43732798  0.1513142  -0.35271707\n",
      "  0.5241084  -0.04563866]\n",
      "\tzvaitwa: [ 0.033958    0.38036603  0.32995132 -0.6968398   0.69241816 -0.12425716\n",
      "  0.44143468 -0.7033672  -0.7865423   0.73048246  0.2120054   0.03874105\n",
      "  0.01356788 -0.00182765 -0.01631158 -0.01717102  0.12624021 -0.8530097\n",
      "  0.7714591  -0.04883799 -0.13802996 -0.8652522   0.22637713  0.20145968\n",
      "  0.7599252   0.64594686  0.3065074  -0.66222876  0.52610177 -0.15526076\n",
      " -0.19593807 -0.35059074 -0.1822194   0.60067004 -0.3908717   0.00270125\n",
      "  0.11149488 -0.28116834  0.10614305  0.5328449  -0.4766743   0.21142147\n",
      "  0.22368982 -0.65676814  0.34347078 -0.23439556  0.32682532 -0.6297405\n",
      "  0.79612356 -0.19278929]\n",
      "\tsei: [-0.64337593 -0.35367182  0.2159376  -0.46165895  0.3938443   0.00128457\n",
      "  0.09777638  0.1758296   0.2427802   0.755508    0.2312617   0.07115532\n",
      "  0.3383715   0.09270989 -0.34008127  0.5456463   0.16219883 -0.0772339\n",
      "  0.24054562 -0.27341855 -0.07755276 -0.8294788   0.39461985  0.3323198\n",
      "  0.05609426  0.4904735   0.1730545  -0.5947433  -0.04223683 -0.39017338\n",
      " -0.21917152 -0.09078673  0.5113737   0.45476755 -0.121207   -0.7467722\n",
      " -0.3669352  -0.2737119   0.6100744  -0.16439697 -0.12572467  0.46979663\n",
      " -0.0741991  -0.8025822   0.21184573 -0.10559852  0.2196642   0.11145781\n",
      "  0.28571773  0.24234061]\n",
      "\t.: [ 0.01686053  0.01679178  0.01255845  0.00920964  0.01229837  0.01313791\n",
      " -0.01748926  0.01971267  0.01324598  0.00737016 -0.01815464  0.01536085\n",
      " -0.0046414   0.01275101  0.01056694  0.00501434 -0.01373173 -0.01937773\n",
      " -0.01645166  0.00743307  0.0100628  -0.01119597  0.00863419  0.0072488\n",
      "  0.00812203 -0.01939026  0.01863839  0.01564768  0.00216114  0.01543188\n",
      "  0.01198145  0.00095703  0.0067538   0.01125299 -0.0149384   0.00403031\n",
      " -0.00797083  0.01764007 -0.0027599  -0.01099936  0.01505769  0.01872787\n",
      "  0.01663026  0.01722633  0.01960812 -0.0110198  -0.00577967  0.01991023\n",
      "  0.01213146  0.01784239]\n",
      "Sentence: Munhu wese anorwadziwa nemutupo wake.\n",
      "Embeddings for words in the sentence:\n",
      "\tMunhu: [-0.18596457  0.00546551 -0.18101443 -0.06795306  0.34844825 -0.29226708\n",
      "  0.3613419  -0.02430286 -0.6501021   0.17510259 -0.11285106 -0.18970416\n",
      "  0.3124158   0.33110434 -0.612867   -0.37339148 -0.13148333  0.16049658\n",
      "  0.06533654 -0.23252805 -0.10738621 -0.32135025  0.51357585  0.02634831\n",
      " -0.0675898   0.20037857  0.14500509 -0.52455795 -0.15614676  0.12327378\n",
      " -0.13215421 -0.10762465  0.2409512   0.15399113 -0.19787414 -0.11358011\n",
      "  0.09651316 -0.02720397  0.10796721 -0.48112148 -0.11842035  0.10450146\n",
      "  0.19356152 -0.56336933  0.12202378 -0.4297826  -0.11033959  0.24935636\n",
      "  0.07647233 -0.35533223]\n",
      "\twese: [ 0.27707165  0.9102575  -0.3644734   0.47666082  0.14405647  0.454252\n",
      " -0.00589533 -0.12223987 -0.27022982  0.18078133 -0.22798614 -2.1993258\n",
      "  1.1818424   0.35500807 -0.08406414  0.07081969 -0.29337785  0.20003204\n",
      "  0.40630984  0.28787124 -0.8987897  -1.5231205   1.9245117  -0.01662983\n",
      " -0.3663818   1.2642137   0.961014   -0.2220952  -0.41274887  0.6201452\n",
      " -0.7528598  -0.71457285  0.17932197 -0.2323072  -0.779215   -1.1484114\n",
      "  0.37888736 -0.18733957  0.7366024   0.5940927  -0.25139055  0.75350523\n",
      "  0.36854506  0.10622633  0.65476    -0.82546645 -1.0689094  -0.3060931\n",
      "  0.5409392   0.7055062 ]\n",
      "\tanorwadziwa: [-0.23774433  0.6362433   0.0682655  -0.3320726   0.2806746   0.10191331\n",
      " -0.06879131  0.21681023 -1.0002555   0.00477896 -0.1663885   0.4312181\n",
      "  0.6485607   0.8904439   0.17825635  0.28146338  0.42741564 -0.06549378\n",
      "  0.27506128 -0.11157064  0.22223128 -0.3434956   0.68884766  0.8321935\n",
      " -0.21893212  0.9306044   0.04042324 -0.5878824   0.5566965   0.11972307\n",
      " -0.03404525  0.42662987  0.18596022  0.42333823 -0.24673764 -0.13592504\n",
      " -0.33631623 -0.41201127  0.04243457 -0.50989777 -0.09852611  0.5443045\n",
      " -0.08849671 -1.092461   -0.3301929  -0.01075043 -0.7199526   0.44051805\n",
      "  0.4380227   0.637446  ]\n",
      "\tnemutupo: [-0.61672926  0.42518127  1.0741777  -0.19881941  0.6077056  -0.25542098\n",
      "  0.32097587  0.44040114 -1.858035   -0.53556347 -0.11968061 -0.4025528\n",
      " -0.429167   -0.6373917  -0.03529555  0.09729496 -0.24235009 -1.3019452\n",
      "  0.07651078 -0.40955585 -0.03027114 -1.5792241   0.08981801 -0.28448635\n",
      "  0.14711615  0.34736824 -0.18963812  0.29688656  0.78377736  0.24269298\n",
      "  0.5926483  -0.79939926  0.1109887  -0.20024443 -0.73270136 -0.22013213\n",
      " -0.50907135 -0.34278056  0.0162587   0.39257485 -0.6464767   0.5424794\n",
      "  0.34242207  0.07211599  0.27104    -0.85730016 -0.2277568  -0.98671454\n",
      "  0.71051323  0.44338164]\n",
      "\twake: [-0.08936331  0.29812142 -0.06531826 -0.36848715 -0.27866513  1.070849\n",
      "  0.31322318 -0.4731253  -0.71257484  0.06739389 -0.91563    -1.0739751\n",
      "  1.7605194   0.28995937  0.48456818 -0.23349062 -0.06093205  0.01438837\n",
      " -0.11644232 -0.14976771 -0.79497707 -0.56351185  1.4900047  -0.35857314\n",
      " -0.10891726  0.97438514  0.7952601   0.30232581 -0.34095383  0.32210538\n",
      " -1.1439224  -0.8770874   0.4851126   0.17795773 -0.9970419   0.10709171\n",
      " -0.06963747 -0.73272794  1.3183686   1.044238   -0.6268705   0.72844106\n",
      " -0.22246382 -0.35497293  0.32209152 -0.45623073 -0.9124686   0.03437476\n",
      "  0.9404785   0.49942917]\n",
      "\t.: [ 0.01686053  0.01679178  0.01255845  0.00920964  0.01229837  0.01313791\n",
      " -0.01748926  0.01971267  0.01324598  0.00737016 -0.01815464  0.01536085\n",
      " -0.0046414   0.01275101  0.01056694  0.00501434 -0.01373173 -0.01937773\n",
      " -0.01645166  0.00743307  0.0100628  -0.01119597  0.00863419  0.0072488\n",
      "  0.00812203 -0.01939026  0.01863839  0.01564768  0.00216114  0.01543188\n",
      "  0.01198145  0.00095703  0.0067538   0.01125299 -0.0149384   0.00403031\n",
      " -0.00797083  0.01764007 -0.0027599  -0.01099936  0.01505769  0.01872787\n",
      "  0.01663026  0.01722633  0.01960812 -0.0110198  -0.00577967  0.01991023\n",
      "  0.01213146  0.01784239]\n",
      "Sentence: Mudzidzisi anorwadziwa nengirozi yake kune yedu.\n",
      "Embeddings for words in the sentence:\n",
      "\tMudzidzisi: [-0.7055799  -0.00276896 -0.15444875 -0.15218076  0.26989898 -0.13789973\n",
      " -0.03628024  0.29542464 -0.65837353  0.47960842  0.48551336 -0.1444282\n",
      " -0.45071074  0.0453589  -0.49131706 -0.2359459  -0.43298912 -0.8184954\n",
      "  0.23441361  0.13451031  0.45314607 -0.5700135   0.35958937  0.18833742\n",
      "  0.01249313  0.08758306  0.73131293 -0.22884123  0.17312184  0.42884567\n",
      " -0.3292613  -0.9588797   0.38607672  0.40707093 -0.05621853 -1.0717747\n",
      "  0.17821713 -0.18777168  0.20663743 -0.06556416  0.4768292   0.31815407\n",
      "  0.16688499 -0.97548485 -0.20938654 -0.40561163 -0.40465817 -0.2356629\n",
      "  0.40076733  0.2551728 ]\n",
      "\tanorwadziwa: [-0.23774433  0.6362433   0.0682655  -0.3320726   0.2806746   0.10191331\n",
      " -0.06879131  0.21681023 -1.0002555   0.00477896 -0.1663885   0.4312181\n",
      "  0.6485607   0.8904439   0.17825635  0.28146338  0.42741564 -0.06549378\n",
      "  0.27506128 -0.11157064  0.22223128 -0.3434956   0.68884766  0.8321935\n",
      " -0.21893212  0.9306044   0.04042324 -0.5878824   0.5566965   0.11972307\n",
      " -0.03404525  0.42662987  0.18596022  0.42333823 -0.24673764 -0.13592504\n",
      " -0.33631623 -0.41201127  0.04243457 -0.50989777 -0.09852611  0.5443045\n",
      " -0.08849671 -1.092461   -0.3301929  -0.01075043 -0.7199526   0.44051805\n",
      "  0.4380227   0.637446  ]\n",
      "\tnengirozi: [ 0.6619952  -0.03382302 -0.00959671 -0.6148964   0.5580384  -0.35269654\n",
      "  0.17482004  0.1135345  -1.0802162  -0.18451706  0.29851502 -0.06173653\n",
      "  0.0743285   0.49844238 -0.4724319   0.09923919  0.06331735 -0.44119972\n",
      " -0.5741566  -0.72985035  0.30872324 -0.37545842  0.51822686  0.2512664\n",
      " -0.0646794   0.7587102   0.08719043 -0.5412404   0.37866342 -0.7310931\n",
      " -0.413161   -0.15775815  0.38935003  0.27107063 -0.21363164  0.24257116\n",
      " -0.2060903  -0.4494522   0.98702055 -0.4986498  -0.5388402   0.525706\n",
      "  0.02106572 -1.4119458   0.5659633  -0.1106007   0.41317198  0.06052604\n",
      " -0.33172113  0.12648922]\n",
      "\tyake: [ 0.20076722 -0.06287707  0.58688873  0.32091707 -0.42014226 -0.00331213\n",
      "  0.3732136  -0.17163487 -0.19896     0.4572449   0.2117117  -0.23892903\n",
      "  0.19195446  0.45007974  0.3436595  -0.36160114  0.40536416 -0.03639399\n",
      "  0.45738515 -0.4180555   0.37208894 -0.44180247  0.68973166  0.16242115\n",
      " -0.62928635  0.25475103  0.46807784 -0.862544    0.6797888   0.39588884\n",
      "  0.1884913  -0.5211952   0.6070175   0.72361505 -0.11843311  0.47753057\n",
      "  0.808144   -0.2543772   0.55021566 -0.00400667  0.10118237  0.16233031\n",
      " -0.24352707 -0.7458227   0.3459543  -0.33365977 -0.5380405   0.0257704\n",
      "  0.33854926  0.81436765]\n",
      "\tkune: [ 0.12825371  0.05118616  0.17694293 -0.12103961  0.5401965   0.02706058\n",
      "  0.01690676  0.35614318 -0.43127486  0.22208907  0.34148413  0.34374037\n",
      " -0.2398272   0.00546442 -0.51016974 -0.292922    0.04055957  0.3137336\n",
      "  0.31454247  0.06061356  0.19492707 -0.78744715  0.70003045  0.00672312\n",
      " -0.14865078 -0.3653983   0.47947684 -0.08252423  0.3624663   0.13398694\n",
      " -0.37334824 -0.49465302  1.1313404   0.56818426  0.06450034 -0.65624654\n",
      "  0.37800062  0.02523123 -0.301422   -0.17322895 -0.07287932  0.68621796\n",
      " -0.7511856  -0.45113504 -0.26262543 -0.43732798  0.1513142  -0.35271707\n",
      "  0.5241084  -0.04563866]\n",
      "\tyedu: [ 0.03962983  0.22693437 -0.04876803 -0.19714855 -0.28920063 -0.2380506\n",
      "  0.18396798  0.00499484  0.17311798  0.7955639   0.34081924 -0.1987655\n",
      " -0.28853095  0.2223116  -0.25042045 -0.06325983 -0.22886081  0.38822776\n",
      "  0.27071497  0.40791786 -0.20831871 -0.8212088   0.5584787   0.17794207\n",
      " -0.3904278  -0.06745689  0.39720523 -0.64783615  0.40349615 -0.06094469\n",
      "  0.770624   -0.73494047  0.4355226   0.61311406  0.52096784 -0.16202042\n",
      "  0.15737365 -0.50424206  0.3676171   0.04494078 -0.3470397   0.34779784\n",
      "  0.19772185 -0.6298616   0.1288357  -0.4774624  -0.00347282 -0.21407795\n",
      "  0.21904102 -0.20035037]\n",
      "\t.: [ 0.01686053  0.01679178  0.01255845  0.00920964  0.01229837  0.01313791\n",
      " -0.01748926  0.01971267  0.01324598  0.00737016 -0.01815464  0.01536085\n",
      " -0.0046414   0.01275101  0.01056694  0.00501434 -0.01373173 -0.01937773\n",
      " -0.01645166  0.00743307  0.0100628  -0.01119597  0.00863419  0.0072488\n",
      "  0.00812203 -0.01939026  0.01863839  0.01564768  0.00216114  0.01543188\n",
      "  0.01198145  0.00095703  0.0067538   0.01125299 -0.0149384   0.00403031\n",
      " -0.00797083  0.01764007 -0.0027599  -0.01099936  0.01505769  0.01872787\n",
      "  0.01663026  0.01722633  0.01960812 -0.0110198  -0.00577967  0.01991023\n",
      "  0.01213146  0.01784239]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from gensim.models import FastText\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Define the GPT-2 tokenization pattern\n",
    "GPT2_SPLIT_PATTERN = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?[a-zA-Z]+| ?[0-9]+| ?[^\\s\\w]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    "\n",
    "# Function to tokenize a sentence using the given pattern\n",
    "def tokenize_sentence(sentence, pattern):\n",
    "    tokens = re.findall(pattern, sentence)\n",
    "    return [token.strip() for token in tokens if token.strip()]\n",
    "\n",
    "# Function to generate embeddings for words in a sentence\n",
    "def generate_embeddings_for_sentence(sentence, model, pattern):\n",
    "    tokens = tokenize_sentence(sentence, pattern)\n",
    "    embeddings = []\n",
    "    for token in tokens:\n",
    "        if token in model.wv:\n",
    "            embeddings.append(model.wv[token])\n",
    "    if not embeddings:\n",
    "        print(\"None of the words in the sentence are in the vocabulary.\")\n",
    "    return embeddings\n",
    "\n",
    "# Example usage\n",
    "sentences = [\n",
    "    \"Ndakanganwa kushandisa tsamba.\",\n",
    "    \"Vatengesi vachabvunza ko ndikati kune zvaitwa sei.\",\n",
    "    \"Munhu wese anorwadziwa nemutupo wake.\",\n",
    "    \"Mudzidzisi anorwadziwa nengirozi yake kune yedu.\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(\"Sentence:\", sentence)\n",
    "    word_embeddings = generate_embeddings_for_sentence(sentence, model, GPT2_SPLIT_PATTERN)\n",
    "    if word_embeddings:\n",
    "        print(\"Embeddings for words in the sentence:\")\n",
    "        for word, embedding in zip(tokenize_sentence(sentence, GPT2_SPLIT_PATTERN), word_embeddings):\n",
    "            print(f\"\\t{word}: {embedding}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Ndakanganwa kushandisa tsamba.\n",
      "Embedding for the sentence: [-0.14047225 -0.23803316  0.16619895  0.18379292  0.06871925  0.13445544\n",
      "  0.22338822 -0.22578679 -0.21422876  0.34511048  0.0599229  -0.40088743\n",
      " -0.17040226  0.13033645 -0.07804136 -0.18858819 -0.04244602  0.05374519\n",
      "  0.06739435 -0.02758298  0.3171039  -0.41982523  0.223082    0.34056607\n",
      " -0.3340216   0.5513506   0.14265826 -0.05882733  0.32952103 -0.09812839\n",
      " -0.07610563 -0.4005863   0.49155954  0.32203057  0.12216822 -0.43812555\n",
      " -0.18406293 -0.3086537  -0.0376423  -0.5159034  -0.19468534  0.28031725\n",
      "  0.28639987 -0.4498237   0.07487646 -0.6891132  -0.02111763 -0.25346535\n",
      "  0.24141502  0.18437183]\n",
      "Sentence: Vatengesi vachabvunza ko ndikati kune zvaitwa sei.\n",
      "Embedding for the sentence: [ 0.32323492  0.2624618   0.5196585  -0.30840778  0.11165506  0.16689028\n",
      " -0.03835896 -0.22733784 -0.48162264  0.08200148  0.34084886  0.03904125\n",
      " -0.10779394 -0.09956083 -0.14196527 -0.00401335 -0.20138554  0.02228521\n",
      "  0.2466386   0.12346923 -0.07593857 -0.8346443   0.4794135   0.21552949\n",
      "  0.16792497  0.23853481  0.20374712 -0.164892    0.519337   -0.19169605\n",
      " -0.07981739 -0.5615807  -0.00782005  0.22356924  0.16828999 -0.04608725\n",
      "  0.00677787 -0.11713213  0.01823531 -0.08728877 -0.04695689  0.32793364\n",
      "  0.02710844 -0.5366407   0.00870212 -0.49769807 -0.14400783 -0.59315354\n",
      "  0.5182462   0.2588679 ]\n",
      "Sentence: Munhu wese anorwadziwa nemutupo wake.\n",
      "Embedding for the sentence: [-0.13931155  0.38201013  0.09069928 -0.08024362  0.18575303  0.18207735\n",
      "  0.15056084  0.00954267 -0.7463252  -0.01668942 -0.26011515 -0.5698298\n",
      "  0.578255    0.20697917 -0.00980587 -0.02538162 -0.0524099  -0.16864996\n",
      "  0.11505408 -0.10135299 -0.26652166 -0.72364974  0.7858986   0.03435021\n",
      " -0.10109711  0.61625993  0.2951171  -0.11994591  0.07213092  0.24056207\n",
      " -0.24305864 -0.3451829   0.20151474  0.05566475 -0.49475142 -0.25115445\n",
      " -0.07459923 -0.2807372   0.36981192  0.17148115 -0.28777108  0.4486599\n",
      "  0.10169972 -0.30253908  0.1765551  -0.4317583  -0.50753444 -0.09144137\n",
      "  0.4530929   0.32471222]\n",
      "Sentence: Mudzidzisi anorwadziwa nengirozi yake kune yedu.\n",
      "Embedding for the sentence: [ 0.01488318  0.11881237  0.09026317 -0.15531588  0.13596629 -0.08426388\n",
      "  0.08947823  0.11928361 -0.45467374  0.25459117  0.2133572   0.02092287\n",
      " -0.00983809  0.3035503  -0.1702652  -0.08114456  0.03729644 -0.09699989\n",
      "  0.13735847 -0.09271453  0.19326581 -0.4786603   0.5033627   0.23230462\n",
      " -0.20448019  0.22562905  0.317475   -0.41931728  0.36519915  0.0431198\n",
      " -0.0255313  -0.3485485   0.44886014  0.4310923  -0.00921302 -0.18597639\n",
      "  0.13876544 -0.25214043  0.26424906 -0.17391512 -0.06631658  0.3718912\n",
      " -0.09727237 -0.7556407   0.03687951 -0.25520468 -0.1582025  -0.03653331\n",
      "  0.22869988  0.22933272]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from gensim.models import FastText\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the GPT-2 tokenization pattern\n",
    "GPT2_SPLIT_PATTERN = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?[a-zA-Z]+| ?[0-9]+| ?[^\\s\\w]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    "\n",
    "# Function to tokenize a sentence using the given pattern\n",
    "def tokenize_sentence(sentence, pattern):\n",
    "    tokens = re.findall(pattern, sentence)\n",
    "    return [token.strip() for token in tokens if token.strip()]\n",
    "\n",
    "# Function to generate embeddings for words in a sentence\n",
    "def generate_sentence_embedding(sentence, model, pattern):\n",
    "    tokens = tokenize_sentence(sentence, pattern)\n",
    "    word_embeddings = []\n",
    "    for token in tokens:\n",
    "        if token in model.wv:\n",
    "            word_embeddings.append(model.wv[token])\n",
    "    if not word_embeddings:\n",
    "        print(\"None of the words in the sentence are in the vocabulary.\")\n",
    "        return None\n",
    "    sentence_embedding = np.mean(word_embeddings, axis=0)\n",
    "    return sentence_embedding\n",
    "\n",
    "# Example usage\n",
    "sentences = [\n",
    "    \"Ndakanganwa kushandisa tsamba.\",\n",
    "    \"Vatengesi vachabvunza ko ndikati kune zvaitwa sei.\",\n",
    "    \"Munhu wese anorwadziwa nemutupo wake.\",\n",
    "    \"Mudzidzisi anorwadziwa nengirozi yake kune yedu.\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(\"Sentence:\", sentence)\n",
    "    sentence_embedding = generate_sentence_embedding(sentence, model, GPT2_SPLIT_PATTERN)\n",
    "    if sentence_embedding is not None:\n",
    "        print(\"Embedding for the sentence:\", sentence_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between sentence 'ndakuenda kuno gara kunyika?' and 'nezuro ndakaenda kumombe ndega': 0.72\n",
      "Similarity between sentence 'Pasi  pano pisa zvisingaite?' and 'pasi pane zuva raka wandisa?': 0.77\n",
      "Similarity between sentence 'sekuru ndivo vakenda kumombe vega?' and 'vasikana vane makuhwa vava?': 0.79\n",
      "Similarity between sentence 'jesu ndiye mwanakona wamwari?' and 'mwari ndiye akasika denga nenyika?': 0.80\n",
      "Similarity between sentence 'Maimboona vasikana vano taurisa here?' and 'vasikana vane makuhwa vava?': 0.84\n"
     ]
    }
   ],
   "source": [
    "# Define the GPT-2 tokenization pattern\n",
    "GPT2_SPLIT_PATTERN = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?[a-zA-Z]+| ?[0-9]+| ?[^\\s\\w]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    "\n",
    "# Function to tokenize a sentence using the given pattern\n",
    "def tokenize_sentence(sentence, pattern):\n",
    "    tokens = re.findall(pattern, sentence)\n",
    "    return [token.strip() for token in tokens if token.strip()]\n",
    "\n",
    "# Function to generate embeddings for words in a sentence\n",
    "def generate_sentence_embedding(sentence, model, pattern):\n",
    "    tokens = tokenize_sentence(sentence, pattern)\n",
    "    word_embeddings = []\n",
    "    for token in tokens:\n",
    "        if token in model.wv:\n",
    "            word_embeddings.append(model.wv[token])\n",
    "    if not word_embeddings:\n",
    "        print(\"None of the words in the sentence are in the vocabulary.\")\n",
    "        return None\n",
    "    sentence_embedding = np.mean(word_embeddings, axis=0)\n",
    "    return sentence_embedding\n",
    "\n",
    "# Function to generate embeddings for sentences\n",
    "def generate_sentence_embeddings(sentences, model, pattern):\n",
    "    sentence_embeddings = []\n",
    "    for sentence in sentences:\n",
    "        embedding = generate_sentence_embedding(sentence, model, pattern)\n",
    "        if embedding is not None:\n",
    "            sentence_embeddings.append(embedding)\n",
    "    return np.array(sentence_embeddings)\n",
    "\n",
    "# Define Shona sentences in lists a and b\n",
    "a = [\n",
    "    \"ndakuenda kuno gara kunyika?\",\n",
    "    \"Pasi  pano pisa zvisingaite?\",\n",
    "    \"sekuru ndivo vakenda kumombe vega?\",\n",
    "    \"jesu ndiye mwanakona wamwari?\",\n",
    "    \"Maimboona vasikana vano taurisa here?\"\n",
    "]\n",
    "\n",
    "b = [\n",
    "    \"mwari ndiye akasika denga nenyika?\",\n",
    "    \"pasi pane zuva raka wandisa?\",\n",
    "    \"nezuro ndakaenda kumombe ndega\",\n",
    "    \"mwari vakasika vanhu nemu fananidzo wedu?\",\n",
    "    \"vasikana vane makuhwa vava?\"\n",
    "]\n",
    "\n",
    "# Calculate cosine similarity between Shona sentences in a and b\n",
    "embeddings_a = generate_sentence_embeddings(a, model, GPT2_SPLIT_PATTERN)\n",
    "embeddings_b = generate_sentence_embeddings(b, model, GPT2_SPLIT_PATTERN)\n",
    "\n",
    "similarity_matrix = cosine_similarity(embeddings_a, embeddings_b)\n",
    "\n",
    "# Find the most similar sentence pairs\n",
    "for i in range(len(a)):\n",
    "    j = similarity_matrix[i].argmax()\n",
    "    similarity_score = similarity_matrix[i][j]\n",
    "    sentence_a = a[i]\n",
    "    sentence_b = b[j]\n",
    "    print(\"Similarity between sentence '{}' and '{}': {:.2f}\".format(sentence_a, sentence_b, similarity_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import load_facebook_model\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "murume is to sekuru as mukadzi is to: sasekuru, kambuya, kunasekuru, anasekuru, vatete\n"
     ]
    }
   ],
   "source": [
    "# Perform Analogical Reasoning\n",
    "def perform_analogical_reasoning(model, a, b, c, topn=5):\n",
    "    # Calculate the vector d as b - a + c\n",
    "    d = model.wv[b] - model.wv[a] + model.wv[c]\n",
    "    \n",
    "    # Find the words that best complete the analogy\n",
    "    closest_words = model.wv.similar_by_vector(d, topn=topn + 3)  # Add extra to ensure we get at least topn unique words\n",
    "    result_words = [word for word, _ in closest_words if word not in [a, b, c]]\n",
    "    \n",
    "    # Ensure we return exactly 'topn' words\n",
    "    return result_words[:topn]\n",
    "\n",
    "# Example usage\n",
    "a = \"murume\"  # man\n",
    "b = \"sekuru\"   # king\n",
    "c = \"mukadzi\" # woman\n",
    "\n",
    "predicted_words = perform_analogical_reasoning(model, a, b, c)\n",
    "if predicted_words:\n",
    "    print(f\"{a} is to {b} as {c} is to: {', '.join(predicted_words)}\")\n",
    "else:\n",
    "    print(\"No suitable words found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['kuvataura', 'nevana', 'vakuru', 'ndokugadzirisa', 'mhosva', 'dzakadaro']\n",
      "Character n-grams: ['k', 'ku', 'kuv', 'u', 'uv', 'uva', 'v', 'va', 'vat', 'a', 'at', 'ata', 't', 'ta', 'tau', 'a', 'au', 'aur', 'u', 'ur', 'ura', 'r', 'ra', 'ra ', 'a', 'a ', 'a n', ' ', ' n', ' ne', 'n', 'ne', 'nev', 'e', 'ev', 'eva', 'v', 'va', 'van', 'a', 'an', 'ana', 'n', 'na', 'na ', 'a', 'a ', 'a v', ' ', ' v', ' va', 'v', 'va', 'vak', 'a', 'ak', 'aku', 'k', 'ku', 'kur', 'u', 'ur', 'uru', 'r', 'ru', 'ru ', 'u', 'u ', 'u n', ' ', ' n', ' nd', 'n', 'nd', 'ndo', 'd', 'do', 'dok', 'o', 'ok', 'oku', 'k', 'ku', 'kug', 'u', 'ug', 'uga', 'g', 'ga', 'gad', 'a', 'ad', 'adz', 'd', 'dz', 'dzi', 'z', 'zi', 'zir', 'i', 'ir', 'iri', 'r', 'ri', 'ris', 'i', 'is', 'isa', 's', 'sa', 'sa ', 'a', 'a ', 'a m', ' ', ' m', ' mh', 'm', 'mh', 'mho', 'h', 'ho', 'hos', 'o', 'os', 'osv', 's', 'sv', 'sva', 'v', 'va', 'va ', 'a', 'a ', 'a d', ' ', ' d', ' dz', 'd', 'dz', 'dza', 'z', 'za', 'zak', 'a', 'ak', 'aka', 'k', 'ka', 'kad', 'a', 'ad', 'ada', 'd', 'da', 'dar', 'a', 'ar', 'aro', 'r', 'ro', 'ro', 'o', 'o', 'o']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_shona_text(text):\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Convert numerals to words (if necessary)\n",
    "    # text = re.sub(r'\\d+', lambda x: num2words(int(x.group())), text)\n",
    "\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tokenization (split text into words)\n",
    "    tokens = re.findall(r'\\b\\w+\\b', text)\n",
    "\n",
    "    # Stemming (remove suffixes and prefixes)\n",
    "    # Example: Convert \"kuvataura\" to \"vataura\" (talk)\n",
    "    # Stemming in Shona can be complex and may require a dictionary-based approach\n",
    "    # Stemming can also be language-specific, so consider using a library or dictionary tailored for Shona\n",
    "    # For simple stemming, you can remove known prefixes and suffixes using regular expressions\n",
    "\n",
    "    # Extract character n-grams\n",
    "    # Example: Convert \"musha\" to [\"mu\", \"ush\", \"sha\"]\n",
    "    # This helps handle rare or misspelled words\n",
    "    char_ngrams = [text[i:i+n] for i in range(len(text)) for n in range(1, 4)]\n",
    "\n",
    "    # Return preprocessed tokens and character n-grams\n",
    "    return tokens, char_ngrams\n",
    "\n",
    "# Example usage\n",
    "text = \"Kuvataura nevana vakuru ndokugadzirisa mhosva dzakadaro.\"\n",
    "tokens, char_ngrams = preprocess_shona_text(text)\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"Character n-grams:\", char_ngrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BEE2\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\BEE2\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "# Define a list of words to visualize\n",
    "words = ['kuenda ', 'misodzi', 'kuchema', 'tsime', 'mvura', 'kugomera', 'mukomana', 'musikana']\n",
    "\n",
    "# Extract the word vectors for the words\n",
    "word_vectors = np.array([model.wv[word] for word in words])\n",
    "\n",
    "# Apply t-SNE to reduce the dimensionality to 2D\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "word_vectors_2d = tsne.fit_transform(word_vectors)\n",
    "\n",
    "# Plot the 2D word vectors\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, word in enumerate(words):\n",
    "    plt.scatter(word_vectors_2d[i, 0], word_vectors_2d[i, 1])\n",
    "    plt.text(word_vectors_2d[i, 0] + 0.01, word_vectors_2d[i, 1] + 0.01, word, fontsize=12)\n",
    "plt.title('t-SNE visualization of FastText word embeddings')\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
